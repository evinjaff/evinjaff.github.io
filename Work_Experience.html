<!DOCTYPE html>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Evin Jaff - Experience</title>
  <link rel="stylesheet" href="./support/lumen-boostrap.min.css">
  <script src="./support/jquery-3.1.1.min.js" integrity="sha256-hVVnYaiADRTO2PzUGmuLJr8BLUSjGIZsDYGmIJLv2b8="
    crossorigin="anonymous"></script>
  <script src="./support/bootstrap.min.js"
    integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous">
  </script>
  <link rel="stylesheet" href="./support/home.css">
  <link rel="stylesheet" href="./support/styles.css">
  <link rel="stylesheet" href="./support/navbar.css">
  <link rel="stylesheet" href="./support/projects.css">
</head>

<body>

  <nav class="navbar navbar-default">
    <div class="container-fluid">
      <div class="site-title">
        <h1>EVIN JAFF</h1>
      </div>

      <hr>

      <!-- Brand and toggle get grouped for better mobile display -->
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
          data-target="#bs-example-navbar-collapse-1" aria-expanded="false">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <!-- <a class="navbar-brand" href="#">Brand</a> -->
      </div>

      <!-- Collect the nav links, forms, and other content for toggling -->
      <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
        <ul class="nav navbar-nav">
          <li><a href="index.html">Home</a></li>
          <li><a href="Press.html">Press</a></li>
          <li class="active"><a href="Work_Experience.html">Experience</a></li>
          <li><a href="Projects.html">Projects</a></li>
          <li><a href="Skills.html">Skills</a></li>
        </ul>

        <ul class="nav navbar-nav nav-float-right">
          <li><a href="https://evinjaff.github.io/papers/evinjaff-resume.pdf">Download Resume</a></li>
        </ul>
      </div><!-- /.navbar-collapse -->
    </div><!-- /.container-fluid -->
  </nav>
  <!-- End Navbar -->

  <div class="container-fluid content">
    <div class="row">
      <div class="col-sm-12">

        <h1>Garmin, <em>Olathe Biosensor Team Intern, Summer 2021</em></h1>

        <div class="photo">
          <img src="./img/pressurewave.png">
          <p>A diagram of a traditional pressure waveform measured by a blood pressure cuff</p>
        </div>

        <p>Currently interning for Garmin as a member of the Biosensor team at their main Olathe campus. The team is
          relatively new
          and was formed as part of a new subdivision called Garmin Health. As an intern, I did two main things,
          research and simulator development.

          Most of my work was on research, but I did help with writing a few patches in C/C++ for the hardware
          simulation of watches. My research was in optical detection of blood pressure using Garmin's smartwatches.
          Garmin's current smartwatch sensors use
          photoplethysmography (PPG) to detect measurements like heart rate with 2-4 green LEDs that emit light around
          the 550 nm wavelength. Additionally, 2-4 infrared lights exist on the same spots as the green LEDS, but are
          infrequently used due to
          the high
          power draw. The quantity of lights depends on the model of smartwatch. For this project, we extracted signal
          readings from both green LED and infrared
          watches and built
          a machine learning pipeline in an attempt to predict blood pressure using signal data. </p>
          <p>The optical signal's shape is equivalent to a pressure waveform from a blood pressure
            cuff (the left diagram shows this blood pressure waveform) but the optical measurement
            presents issues in reliability. While the PPG signal has the same shape, the values of the signal
            has very little correlation to the actual blood pressure and vary wildly from subject to subject (and
            even trial to trial). As a result, additional estimation steps and alternative features were prototyped to account for this. </p>

        <p>Over the summer, I developed 3 distinct pipelines with my mentor, and found moderate
          statistical correlation when extensive signal processing was applied. Despite a somewhat successful correlation, we ultimately determined that optical estimation with Garmin's existing sensor
          arrays was not feasible, but that optical estimation shows promise. The conclusion was that the next generation
          sensor array would need to be improved and that Garmin would include hardware similar to <a
            href="https://livemetric.net/">LiveMetric's recently 510k FDA-Approved sensor array.</a> </p>
        
        <p>Notable competitors in the space such as Apple,
          Samsung, and Withings have had meddling success attempting similar projects, with only Samsung having mild
          success
          releasing <a
            href="https://www.theverge.com/2021/9/16/22677381/smartwatch-blood-pressure-samsung-fitbit-apple">blood
            pressure detection in the asian markets</a>, but not into the North American or
          European markets where medical device regulations tend to be stricter.</p>
            

        <h1>Washington University School of Medicine, <em>Undergraduate Researcher, Summer 2021</em></h1>

        <div class="photo">
          <img src="./img/chenlab.png">
          <p>Photo of the interface scoring a sleep experiment</p>
        </div>

        <p>Researcher at the Chen Lab at the Washington University School of Medicine studying sleep in lab mice. As an
          undergraduate researcher, I developed and maintained a tool to analyze and mice sleep to different states
          (REM, NREM, etc). I added additional features and modules to a machine learning pipeline written by a graduate
          student.
          New features included a system for versioning trained models to track overtraining, giving the
          model the ability to identify a new state called "quiet wakefullness" to better classify intermediate states
          of wakefullness, and the ability to dynamically click on a spectrogram and see detailed LFP, EMG, Delta, and
          Theta signals to closely analyze problem areas the model couldn't identify. In addition to maintaining these
          features, I became an active member of the lab and attended biweekly journal clubs where I learned and
          discussed academic papers on various neuromodulation topics.</p>
        <p>The project continues to be maintained by the lab since I stopped working there, and a link to the GitHub
          repository can be found <a rel="noopener noreferrer" target="_blank"
            href="https://github.com/YaoChenLab/neuroscience_sleep_scoring">here</a></p>
        <br>
        <br>
        <h1>Washington University in St. Louis, <em>Teaching Assistant, Spring 2020-Present</em></h1>

        <p>
          Since 2020, I have been a TA and Tutor for Washington University in St. Louis. A breakdown of my positions
          starting from most recent is shown below
        </p>

        <ul>
          <li>TA for Washington University: </li>
          <!-- <li>Head TA, CSE 237: Programming Tools and Techniques (Spring 2022)</li> -->
          <li>Section Lead, CSE 247: Data Structures and Algorithms (Fall 2022)</li>
          <li>TA, CSE 247: Data Structures and Algorithms (Spring 2021 - Fall 2022)</li>
          <li>Tutor, CSE 131: Introduction to Computer Science (Fall 2020 - Spring 2021)</li>
        </ul>

        <h1>Department of Defense: Project Tesseract, <em>Intern, Summer 2020</em></h1>

        <p>
          Project Tesseract is an effort by the United States Department of Defense to gain insights from recruited
          fellows in academia on emerging fields and for the fellows to work on projects related to the research of
          emerging technologies.</p>

        <p>
          While an unpaid fellow, I prototyped a vending system for tools to accelerate the speed of maintenance
          operations on a military base's Flightline. I also worked on a sub-team to develop a system to allow for
          autonomous robots to operate
          inside a hangar among humans similar to Amazon fulfillment centers. I also presented a report of the robot
          system to Brigadier General Linda Hurry, where it was positively received. </p>

        <h1>OsteoPOP, <em>Engineering Lead, Fall-Spring 2019-2020</em></h1>

        <div class="photo">
          <img src="./img/we1.png">
          <p>Diagram from the provisional patent</p>
        </div>

        <p>OsteoPOP was a student startup led by Biomedical Engineering Ph.D. student Ian Berke. OsteoPOP focused on
          finding a solution to the low compliance rate of bisphosphonate medications prescribed to elderly women for
          the treatment of
          Osteoporosis. </p>
        <p>Our team spanned a wide array of disciplines, including students skilled in Biomedical Engineering like Ian
          and I, an Electrical and Systems Engineering Student proficient in sensors, two Economics Ph.D. students
          studying incentives, and
          MBA students studying the market of a potential solution. </p>
        <p>Our solution was a device with an optional pack-in application that tracked compliance and educated the user
          on the importance of their medication as well as auto-requested a prescription refill for them if they
          consented to it. As an
          Engineering Lead, I managed the development schedule and still worked as an engineer helping with the
          development of a prototype, which included microcontroller programming, Computer-Aided Design (CAD), and App
          Development. Our final result
          was simple, yet effective; a pill cap sensor that was equipped with a LIDAR sensor and 3D Dot Projection that
          could estimate the number of pills left in the bottle accurately enough to determine whether a medication was
          taken and if a
          refill would soon be required. The resulting device was filed for a <a
            href="https://evinjaff.github.io/papers/Berke,%20Jaff,%20Martin%20-%202020.pdf">provisional patent
            co-authored by Evin Jaff, Ian Berke, and Caleb Martin</a> (the three
          main students working on prototyping the device). The prototype was presented at multiple entrepreneurship
          events, including TigerLaunch, and Washington University's Olin School of Business' Idea Bounce where it was a
          finalist in both. The
          student startup disbanded, however, after Ian was awarded his Ph.D. in the Spring of 2019.</p>

        <h1>University of Washington School of Medicine, <em>Research Intern, Summer 2019</em></h1>

        <div class="photo">
          <img src="./img/we2.png">
          <p>A photo of a sample similar to what I prepared in a recent publication from the lab</p>
        </div>

        <p>While interning at the Stone Lab in the Medical School's Otolaryngology Department, I worked under a graduate
          student to prepare and analyze inner-ear samples. I learned standard lab skills, as well as complex protocols
          for how to properly
          "defrost" biological samples stored for years in sub-zero freezers and the handling of dangerous chemicals
          such as Formaldehyde. While an intern, I also attended multiple research conferences and met with colleagues
          of the lab to learn more
          about medical research </p>
      </div>
      <br><br>
    </div>

  </div>
  <br><br>


</body>

</html>